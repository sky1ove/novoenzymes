{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/facebookresearch/esm.git -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import esm\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm; tqdm.pandas()\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t33_650M_UR50D.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t33_650M_UR50D.pt\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/regression/esm2_t33_650M_UR50D-contact-regression.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t33_650M_UR50D-contact-regression.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ESM2(\n",
       "  (embed_tokens): Embedding(33, 1280, padding_idx=1)\n",
       "  (layers): ModuleList(\n",
       "    (0): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (4): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (5): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (6): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (7): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (8): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (9): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (10): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (11): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (12): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (13): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (14): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (15): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (16): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (17): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (18): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (19): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (20): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (21): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (22): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (23): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (24): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (25): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (26): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (27): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (28): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (29): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (30): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (31): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (32): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (contact_head): ContactPredictionHead(\n",
       "    (regression): Linear(in_features=660, out_features=1, bias=True)\n",
       "    (activation): Sigmoid()\n",
       "  )\n",
       "  (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load ESM-2 model\n",
    "model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "model.eval()  # disables dropout for deterministic results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferred model to GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    print(\"Transferred model to GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('all_enzymes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(r):\n",
    "    data = [('protein',r.protein_sequence)]\n",
    "    labels, strs, tokens = batch_converter(data)\n",
    "    with torch.no_grad(): \n",
    "        results = model(tokens.cuda(), repr_layers=[33], return_contacts=True)\n",
    "    rpr = results[\"representations\"][33].squeeze()\n",
    "    rpr=rpr[1 : len(r.protein_sequence) + 1].mean(0).detach().cpu().numpy()\n",
    "    \n",
    "    del results, labels, strs, tokens, data #especially need to delete those on cuda: tokens, results\n",
    "    \n",
    "    return rpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 15 21:14:53 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.73.05    Driver Version: 510.73.05    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:05.0 Off |                   0* |\n",
      "| N/A   45C    P0    89W / 500W |  68033MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi #check Memory-Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_df(df):\n",
    "    series = df.progress_apply(get_feature, axis=1)\n",
    "    df_feature = pd.DataFrame(series.tolist())\n",
    "    return df_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['len'] = df.protein_sequence.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.sort_values(by='len', ascending=False).iloc[17:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c8d587a19c4bffafd80ae9ff17816c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6591 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_feature = get_feature_df(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_id</th>\n",
       "      <th>protein_sequence</th>\n",
       "      <th>pH</th>\n",
       "      <th>data_source</th>\n",
       "      <th>tm</th>\n",
       "      <th>x</th>\n",
       "      <th>group</th>\n",
       "      <th>wildtype</th>\n",
       "      <th>split</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4107</th>\n",
       "      <td>20930</td>\n",
       "      <td>MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.1371/journal.pone.0032654</td>\n",
       "      <td>51.6</td>\n",
       "      <td>1159.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...</td>\n",
       "      <td>train</td>\n",
       "      <td>1159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4103</th>\n",
       "      <td>20926</td>\n",
       "      <td>MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.1371/journal.pone.0032654</td>\n",
       "      <td>45.4</td>\n",
       "      <td>1159.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...</td>\n",
       "      <td>train</td>\n",
       "      <td>1159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4102</th>\n",
       "      <td>20925</td>\n",
       "      <td>MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.1371/journal.pone.0032654</td>\n",
       "      <td>60.2</td>\n",
       "      <td>1159.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...</td>\n",
       "      <td>train</td>\n",
       "      <td>1159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4101</th>\n",
       "      <td>20924</td>\n",
       "      <td>MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.1371/journal.pone.0032654</td>\n",
       "      <td>57.7</td>\n",
       "      <td>1159.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...</td>\n",
       "      <td>train</td>\n",
       "      <td>1159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4109</th>\n",
       "      <td>20932</td>\n",
       "      <td>MPVRRGHVAPQNTFLDTIIRKFEGQSRKLIIANARVENCAVIYCND...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.1371/journal.pone.0032654</td>\n",
       "      <td>51.8</td>\n",
       "      <td>1159.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...</td>\n",
       "      <td>train</td>\n",
       "      <td>1159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3215</th>\n",
       "      <td>13940</td>\n",
       "      <td>MKGMAKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>10.1038/nsb0894-518</td>\n",
       "      <td>57.5</td>\n",
       "      <td>53.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>MKGMSKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...</td>\n",
       "      <td>train</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3214</th>\n",
       "      <td>13909</td>\n",
       "      <td>MKGASKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>10.1038/nsb0894-518</td>\n",
       "      <td>59.2</td>\n",
       "      <td>53.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>MKGMSKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...</td>\n",
       "      <td>train</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3213</th>\n",
       "      <td>13586</td>\n",
       "      <td>MKAMSKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>10.1038/nsb0894-518</td>\n",
       "      <td>58.1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>MKGMSKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...</td>\n",
       "      <td>train</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3212</th>\n",
       "      <td>4618</td>\n",
       "      <td>MAGMSKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>10.1038/nsb0894-518</td>\n",
       "      <td>58.7</td>\n",
       "      <td>53.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>MKGMSKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...</td>\n",
       "      <td>train</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3236</th>\n",
       "      <td>13969</td>\n",
       "      <td>MKGMSKMPQFNLRWPREVLDLVRKVAAENGRSVNSEIYQRVMESFK...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>10.1038/nsb0894-518</td>\n",
       "      <td>58.8</td>\n",
       "      <td>53.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>MKGMSKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...</td>\n",
       "      <td>train</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6591 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      seq_id                                   protein_sequence   pH  \\\n",
       "4107   20930  MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...  8.0   \n",
       "4103   20926  MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...  8.0   \n",
       "4102   20925  MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...  8.0   \n",
       "4101   20924  MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...  8.0   \n",
       "4109   20932  MPVRRGHVAPQNTFLDTIIRKFEGQSRKLIIANARVENCAVIYCND...  8.0   \n",
       "...      ...                                                ...  ...   \n",
       "3215   13940  MKGMAKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...  7.5   \n",
       "3214   13909  MKGASKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...  7.5   \n",
       "3213   13586  MKAMSKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...  7.5   \n",
       "3212    4618  MAGMSKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...  7.5   \n",
       "3236   13969  MKGMSKMPQFNLRWPREVLDLVRKVAAENGRSVNSEIYQRVMESFK...  7.5   \n",
       "\n",
       "                       data_source    tm       x  group  \\\n",
       "4107  10.1371/journal.pone.0032654  51.6  1159.0   65.0   \n",
       "4103  10.1371/journal.pone.0032654  45.4  1159.0   65.0   \n",
       "4102  10.1371/journal.pone.0032654  60.2  1159.0   65.0   \n",
       "4101  10.1371/journal.pone.0032654  57.7  1159.0   65.0   \n",
       "4109  10.1371/journal.pone.0032654  51.8  1159.0   65.0   \n",
       "...                            ...   ...     ...    ...   \n",
       "3215           10.1038/nsb0894-518  57.5    53.0   25.0   \n",
       "3214           10.1038/nsb0894-518  59.2    53.0   25.0   \n",
       "3213           10.1038/nsb0894-518  58.1    53.0   25.0   \n",
       "3212           10.1038/nsb0894-518  58.7    53.0   25.0   \n",
       "3236           10.1038/nsb0894-518  58.8    53.0   25.0   \n",
       "\n",
       "                                               wildtype  split   len  \n",
       "4107  MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...  train  1159  \n",
       "4103  MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...  train  1159  \n",
       "4102  MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...  train  1159  \n",
       "4101  MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...  train  1159  \n",
       "4109  MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...  train  1159  \n",
       "...                                                 ...    ...   ...  \n",
       "3215  MKGMSKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...  train    53  \n",
       "3214  MKGMSKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...  train    53  \n",
       "3213  MKGMSKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...  train    53  \n",
       "3212  MKGMSKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...  train    53  \n",
       "3236  MKGMSKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...  train    53  \n",
       "\n",
       "[6591 rows x 10 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6591"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seq_id</th>\n",
       "      <th>protein_sequence</th>\n",
       "      <th>pH</th>\n",
       "      <th>data_source</th>\n",
       "      <th>tm</th>\n",
       "      <th>x</th>\n",
       "      <th>group</th>\n",
       "      <th>wildtype</th>\n",
       "      <th>split</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4107</td>\n",
       "      <td>20930</td>\n",
       "      <td>MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.1371/journal.pone.0032654</td>\n",
       "      <td>51.6</td>\n",
       "      <td>1159.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...</td>\n",
       "      <td>train</td>\n",
       "      <td>1159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4103</td>\n",
       "      <td>20926</td>\n",
       "      <td>MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.1371/journal.pone.0032654</td>\n",
       "      <td>45.4</td>\n",
       "      <td>1159.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...</td>\n",
       "      <td>train</td>\n",
       "      <td>1159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4102</td>\n",
       "      <td>20925</td>\n",
       "      <td>MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.1371/journal.pone.0032654</td>\n",
       "      <td>60.2</td>\n",
       "      <td>1159.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...</td>\n",
       "      <td>train</td>\n",
       "      <td>1159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4101</td>\n",
       "      <td>20924</td>\n",
       "      <td>MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.1371/journal.pone.0032654</td>\n",
       "      <td>57.7</td>\n",
       "      <td>1159.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...</td>\n",
       "      <td>train</td>\n",
       "      <td>1159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4109</td>\n",
       "      <td>20932</td>\n",
       "      <td>MPVRRGHVAPQNTFLDTIIRKFEGQSRKLIIANARVENCAVIYCND...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.1371/journal.pone.0032654</td>\n",
       "      <td>51.8</td>\n",
       "      <td>1159.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...</td>\n",
       "      <td>train</td>\n",
       "      <td>1159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6586</th>\n",
       "      <td>3215</td>\n",
       "      <td>13940</td>\n",
       "      <td>MKGMAKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>10.1038/nsb0894-518</td>\n",
       "      <td>57.5</td>\n",
       "      <td>53.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>MKGMSKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...</td>\n",
       "      <td>train</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6587</th>\n",
       "      <td>3214</td>\n",
       "      <td>13909</td>\n",
       "      <td>MKGASKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>10.1038/nsb0894-518</td>\n",
       "      <td>59.2</td>\n",
       "      <td>53.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>MKGMSKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...</td>\n",
       "      <td>train</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6588</th>\n",
       "      <td>3213</td>\n",
       "      <td>13586</td>\n",
       "      <td>MKAMSKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>10.1038/nsb0894-518</td>\n",
       "      <td>58.1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>MKGMSKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...</td>\n",
       "      <td>train</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6589</th>\n",
       "      <td>3212</td>\n",
       "      <td>4618</td>\n",
       "      <td>MAGMSKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>10.1038/nsb0894-518</td>\n",
       "      <td>58.7</td>\n",
       "      <td>53.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>MKGMSKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...</td>\n",
       "      <td>train</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6590</th>\n",
       "      <td>3236</td>\n",
       "      <td>13969</td>\n",
       "      <td>MKGMSKMPQFNLRWPREVLDLVRKVAAENGRSVNSEIYQRVMESFK...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>10.1038/nsb0894-518</td>\n",
       "      <td>58.8</td>\n",
       "      <td>53.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>MKGMSKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...</td>\n",
       "      <td>train</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6591 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  seq_id                                   protein_sequence   pH  \\\n",
       "0      4107   20930  MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...  8.0   \n",
       "1      4103   20926  MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...  8.0   \n",
       "2      4102   20925  MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...  8.0   \n",
       "3      4101   20924  MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...  8.0   \n",
       "4      4109   20932  MPVRRGHVAPQNTFLDTIIRKFEGQSRKLIIANARVENCAVIYCND...  8.0   \n",
       "...     ...     ...                                                ...  ...   \n",
       "6586   3215   13940  MKGMAKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...  7.5   \n",
       "6587   3214   13909  MKGASKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...  7.5   \n",
       "6588   3213   13586  MKAMSKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...  7.5   \n",
       "6589   3212    4618  MAGMSKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...  7.5   \n",
       "6590   3236   13969  MKGMSKMPQFNLRWPREVLDLVRKVAAENGRSVNSEIYQRVMESFK...  7.5   \n",
       "\n",
       "                       data_source    tm       x  group  \\\n",
       "0     10.1371/journal.pone.0032654  51.6  1159.0   65.0   \n",
       "1     10.1371/journal.pone.0032654  45.4  1159.0   65.0   \n",
       "2     10.1371/journal.pone.0032654  60.2  1159.0   65.0   \n",
       "3     10.1371/journal.pone.0032654  57.7  1159.0   65.0   \n",
       "4     10.1371/journal.pone.0032654  51.8  1159.0   65.0   \n",
       "...                            ...   ...     ...    ...   \n",
       "6586           10.1038/nsb0894-518  57.5    53.0   25.0   \n",
       "6587           10.1038/nsb0894-518  59.2    53.0   25.0   \n",
       "6588           10.1038/nsb0894-518  58.1    53.0   25.0   \n",
       "6589           10.1038/nsb0894-518  58.7    53.0   25.0   \n",
       "6590           10.1038/nsb0894-518  58.8    53.0   25.0   \n",
       "\n",
       "                                               wildtype  split   len  \n",
       "0     MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...  train  1159  \n",
       "1     MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...  train  1159  \n",
       "2     MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...  train  1159  \n",
       "3     MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...  train  1159  \n",
       "4     MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...  train  1159  \n",
       "...                                                 ...    ...   ...  \n",
       "6586  MKGMSKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...  train    53  \n",
       "6587  MKGMSKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...  train    53  \n",
       "6588  MKGMSKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...  train    53  \n",
       "6589  MKGMSKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...  train    53  \n",
       "6590  MKGMSKMPQFNLRWPREVLDLVRKVAEENGRSVNSEIYQRVMESFK...  train    53  \n",
       "\n",
       "[6591 rows x 11 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.reset_index(inplace=True) #make sure the index of two concat dfs are same\n",
    "df_combine = pd.concat([df2, df_feature], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>seq_id</th>\n",
       "      <th>protein_sequence</th>\n",
       "      <th>pH</th>\n",
       "      <th>data_source</th>\n",
       "      <th>tm</th>\n",
       "      <th>x</th>\n",
       "      <th>group</th>\n",
       "      <th>wildtype</th>\n",
       "      <th>...</th>\n",
       "      <th>1270</th>\n",
       "      <th>1271</th>\n",
       "      <th>1272</th>\n",
       "      <th>1273</th>\n",
       "      <th>1274</th>\n",
       "      <th>1275</th>\n",
       "      <th>1276</th>\n",
       "      <th>1277</th>\n",
       "      <th>1278</th>\n",
       "      <th>1279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4107</td>\n",
       "      <td>20930</td>\n",
       "      <td>MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.1371/journal.pone.0032654</td>\n",
       "      <td>51.6</td>\n",
       "      <td>1159.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031775</td>\n",
       "      <td>-0.031993</td>\n",
       "      <td>-0.104209</td>\n",
       "      <td>0.057127</td>\n",
       "      <td>-0.052359</td>\n",
       "      <td>-0.003870</td>\n",
       "      <td>-0.019295</td>\n",
       "      <td>-0.056855</td>\n",
       "      <td>0.027195</td>\n",
       "      <td>0.079772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4103</td>\n",
       "      <td>20926</td>\n",
       "      <td>MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.1371/journal.pone.0032654</td>\n",
       "      <td>45.4</td>\n",
       "      <td>1159.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030997</td>\n",
       "      <td>-0.033303</td>\n",
       "      <td>-0.103292</td>\n",
       "      <td>0.056217</td>\n",
       "      <td>-0.052639</td>\n",
       "      <td>-0.004553</td>\n",
       "      <td>-0.019764</td>\n",
       "      <td>-0.058243</td>\n",
       "      <td>0.027680</td>\n",
       "      <td>0.081486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4102</td>\n",
       "      <td>20925</td>\n",
       "      <td>MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.1371/journal.pone.0032654</td>\n",
       "      <td>60.2</td>\n",
       "      <td>1159.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031284</td>\n",
       "      <td>-0.034017</td>\n",
       "      <td>-0.101006</td>\n",
       "      <td>0.056126</td>\n",
       "      <td>-0.052612</td>\n",
       "      <td>-0.002814</td>\n",
       "      <td>-0.019347</td>\n",
       "      <td>-0.058032</td>\n",
       "      <td>0.027677</td>\n",
       "      <td>0.080875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4101</td>\n",
       "      <td>20924</td>\n",
       "      <td>MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.1371/journal.pone.0032654</td>\n",
       "      <td>57.7</td>\n",
       "      <td>1159.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030985</td>\n",
       "      <td>-0.032532</td>\n",
       "      <td>-0.103684</td>\n",
       "      <td>0.054506</td>\n",
       "      <td>-0.052623</td>\n",
       "      <td>-0.003652</td>\n",
       "      <td>-0.019665</td>\n",
       "      <td>-0.057412</td>\n",
       "      <td>0.027688</td>\n",
       "      <td>0.080774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4109</td>\n",
       "      <td>20932</td>\n",
       "      <td>MPVRRGHVAPQNTFLDTIIRKFEGQSRKLIIANARVENCAVIYCND...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.1371/journal.pone.0032654</td>\n",
       "      <td>51.8</td>\n",
       "      <td>1159.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030114</td>\n",
       "      <td>-0.033987</td>\n",
       "      <td>-0.104270</td>\n",
       "      <td>0.057183</td>\n",
       "      <td>-0.052627</td>\n",
       "      <td>-0.002089</td>\n",
       "      <td>-0.022006</td>\n",
       "      <td>-0.059038</td>\n",
       "      <td>0.026654</td>\n",
       "      <td>0.080276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1292 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index  seq_id                                   protein_sequence  \\\n",
       "0        0   4107   20930  MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...   \n",
       "1        1   4103   20926  MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...   \n",
       "2        2   4102   20925  MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...   \n",
       "3        3   4101   20924  MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...   \n",
       "4        4   4109   20932  MPVRRGHVAPQNTFLDTIIRKFEGQSRKLIIANARVENCAVIYCND...   \n",
       "\n",
       "    pH                   data_source    tm       x  group  \\\n",
       "0  8.0  10.1371/journal.pone.0032654  51.6  1159.0   65.0   \n",
       "1  8.0  10.1371/journal.pone.0032654  45.4  1159.0   65.0   \n",
       "2  8.0  10.1371/journal.pone.0032654  60.2  1159.0   65.0   \n",
       "3  8.0  10.1371/journal.pone.0032654  57.7  1159.0   65.0   \n",
       "4  8.0  10.1371/journal.pone.0032654  51.8  1159.0   65.0   \n",
       "\n",
       "                                            wildtype  ...      1270      1271  \\\n",
       "0  MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...  ...  0.031775 -0.031993   \n",
       "1  MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...  ...  0.030997 -0.033303   \n",
       "2  MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...  ...  0.031284 -0.034017   \n",
       "3  MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...  ...  0.030985 -0.032532   \n",
       "4  MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...  ...  0.030114 -0.033987   \n",
       "\n",
       "       1272      1273      1274      1275      1276      1277      1278  \\\n",
       "0 -0.104209  0.057127 -0.052359 -0.003870 -0.019295 -0.056855  0.027195   \n",
       "1 -0.103292  0.056217 -0.052639 -0.004553 -0.019764 -0.058243  0.027680   \n",
       "2 -0.101006  0.056126 -0.052612 -0.002814 -0.019347 -0.058032  0.027677   \n",
       "3 -0.103684  0.054506 -0.052623 -0.003652 -0.019665 -0.057412  0.027688   \n",
       "4 -0.104270  0.057183 -0.052627 -0.002089 -0.022006 -0.059038  0.026654   \n",
       "\n",
       "       1279  \n",
       "0  0.079772  \n",
       "1  0.081486  \n",
       "2  0.080875  \n",
       "3  0.080774  \n",
       "4  0.080276  \n",
       "\n",
       "[5 rows x 1292 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6591"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combine.to_csv('all_enzymes_feature.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect();torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get WT feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wt = pd.DataFrame(df2.wildtype.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wt.rename(columns={0: 'protein_sequence'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ec8d1e790c4a93abd0c2240bddd63f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wt_feature = get_feature_df(df_wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_combine = pd.concat([df_wt, wt_feature], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_combine.to_csv('wildtype_feature.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get WT-mutant differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein_sequence</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>1270</th>\n",
       "      <th>1271</th>\n",
       "      <th>1272</th>\n",
       "      <th>1273</th>\n",
       "      <th>1274</th>\n",
       "      <th>1275</th>\n",
       "      <th>1276</th>\n",
       "      <th>1277</th>\n",
       "      <th>1278</th>\n",
       "      <th>1279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...</td>\n",
       "      <td>0.015805</td>\n",
       "      <td>-0.033919</td>\n",
       "      <td>0.005356</td>\n",
       "      <td>-0.001142</td>\n",
       "      <td>-0.037829</td>\n",
       "      <td>-0.062076</td>\n",
       "      <td>0.034698</td>\n",
       "      <td>0.074689</td>\n",
       "      <td>0.025458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031189</td>\n",
       "      <td>-0.033546</td>\n",
       "      <td>-0.103467</td>\n",
       "      <td>0.056230</td>\n",
       "      <td>-0.052916</td>\n",
       "      <td>-0.003619</td>\n",
       "      <td>-0.020674</td>\n",
       "      <td>-0.058185</td>\n",
       "      <td>0.027794</td>\n",
       "      <td>0.081028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MEELQDDYEDMMEENLEQEEYEDPDIPESQMEEPAAHDTEATATDY...</td>\n",
       "      <td>-0.017728</td>\n",
       "      <td>0.002291</td>\n",
       "      <td>-0.005282</td>\n",
       "      <td>-0.005080</td>\n",
       "      <td>-0.027136</td>\n",
       "      <td>-0.036133</td>\n",
       "      <td>0.065131</td>\n",
       "      <td>0.004717</td>\n",
       "      <td>0.007467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056245</td>\n",
       "      <td>0.033457</td>\n",
       "      <td>-0.124666</td>\n",
       "      <td>-0.020386</td>\n",
       "      <td>0.027567</td>\n",
       "      <td>-0.074638</td>\n",
       "      <td>0.048811</td>\n",
       "      <td>-0.047698</td>\n",
       "      <td>0.007801</td>\n",
       "      <td>0.049899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MTDITANVVVSNPRPIFTESRSFKAVANGKIYIGQIDTDPVNPANQ...</td>\n",
       "      <td>0.016938</td>\n",
       "      <td>0.050288</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>-0.010340</td>\n",
       "      <td>-0.100914</td>\n",
       "      <td>0.016280</td>\n",
       "      <td>0.007097</td>\n",
       "      <td>-0.068371</td>\n",
       "      <td>0.050936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037742</td>\n",
       "      <td>-0.022452</td>\n",
       "      <td>0.080056</td>\n",
       "      <td>0.028671</td>\n",
       "      <td>0.020483</td>\n",
       "      <td>0.058210</td>\n",
       "      <td>0.075229</td>\n",
       "      <td>-0.084503</td>\n",
       "      <td>0.046309</td>\n",
       "      <td>0.086032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MSSRKELANAIRALSMDAVQKAKSGHPGAPMGMADIAEVLWRDFLK...</td>\n",
       "      <td>-0.011090</td>\n",
       "      <td>0.016666</td>\n",
       "      <td>-0.012930</td>\n",
       "      <td>0.030634</td>\n",
       "      <td>-0.012921</td>\n",
       "      <td>-0.012898</td>\n",
       "      <td>0.045492</td>\n",
       "      <td>-0.175886</td>\n",
       "      <td>0.034107</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067271</td>\n",
       "      <td>-0.067047</td>\n",
       "      <td>-0.062890</td>\n",
       "      <td>-0.037578</td>\n",
       "      <td>-0.029985</td>\n",
       "      <td>0.007193</td>\n",
       "      <td>0.019816</td>\n",
       "      <td>-0.198807</td>\n",
       "      <td>-0.022456</td>\n",
       "      <td>0.110925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MRPSLPPLLTCLLAALPALLSAGCSPATPSAHAAEPASRNVPFPYA...</td>\n",
       "      <td>-0.005208</td>\n",
       "      <td>-0.068409</td>\n",
       "      <td>0.039885</td>\n",
       "      <td>-0.062333</td>\n",
       "      <td>0.012764</td>\n",
       "      <td>-0.049863</td>\n",
       "      <td>0.015773</td>\n",
       "      <td>-0.156441</td>\n",
       "      <td>-0.020250</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021826</td>\n",
       "      <td>-0.072720</td>\n",
       "      <td>-0.002612</td>\n",
       "      <td>-0.078776</td>\n",
       "      <td>-0.078234</td>\n",
       "      <td>0.016206</td>\n",
       "      <td>0.081448</td>\n",
       "      <td>-0.206387</td>\n",
       "      <td>0.055972</td>\n",
       "      <td>0.011760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1281 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    protein_sequence         0         1  \\\n",
       "0  MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCND...  0.015805 -0.033919   \n",
       "1  MEELQDDYEDMMEENLEQEEYEDPDIPESQMEEPAAHDTEATATDY... -0.017728  0.002291   \n",
       "2  MTDITANVVVSNPRPIFTESRSFKAVANGKIYIGQIDTDPVNPANQ...  0.016938  0.050288   \n",
       "3  MSSRKELANAIRALSMDAVQKAKSGHPGAPMGMADIAEVLWRDFLK... -0.011090  0.016666   \n",
       "4  MRPSLPPLLTCLLAALPALLSAGCSPATPSAHAAEPASRNVPFPYA... -0.005208 -0.068409   \n",
       "\n",
       "          2         3         4         5         6         7         8  ...  \\\n",
       "0  0.005356 -0.001142 -0.037829 -0.062076  0.034698  0.074689  0.025458  ...   \n",
       "1 -0.005282 -0.005080 -0.027136 -0.036133  0.065131  0.004717  0.007467  ...   \n",
       "2  0.001779 -0.010340 -0.100914  0.016280  0.007097 -0.068371  0.050936  ...   \n",
       "3 -0.012930  0.030634 -0.012921 -0.012898  0.045492 -0.175886  0.034107  ...   \n",
       "4  0.039885 -0.062333  0.012764 -0.049863  0.015773 -0.156441 -0.020250  ...   \n",
       "\n",
       "       1270      1271      1272      1273      1274      1275      1276  \\\n",
       "0  0.031189 -0.033546 -0.103467  0.056230 -0.052916 -0.003619 -0.020674   \n",
       "1  0.056245  0.033457 -0.124666 -0.020386  0.027567 -0.074638  0.048811   \n",
       "2  0.037742 -0.022452  0.080056  0.028671  0.020483  0.058210  0.075229   \n",
       "3 -0.067271 -0.067047 -0.062890 -0.037578 -0.029985  0.007193  0.019816   \n",
       "4 -0.021826 -0.072720 -0.002612 -0.078776 -0.078234  0.016206  0.081448   \n",
       "\n",
       "       1277      1278      1279  \n",
       "0 -0.058185  0.027794  0.081028  \n",
       "1 -0.047698  0.007801  0.049899  \n",
       "2 -0.084503  0.046309  0.086032  \n",
       "3 -0.198807 -0.022456  0.110925  \n",
       "4 -0.206387  0.055972  0.011760  \n",
       "\n",
       "[5 rows x 1281 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_combine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_combine.rename(columns={'protein_sequence': 'wildtype'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_enzymes_wildtype_feature = df_combine[['wildtype']].merge(wt_combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_enzymes_wildtype_feature.to_csv('all_enzymes_wildtype_feature.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get WT-mutant differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wt = pd.read_csv('all_enzymes_wildtype_feature.csv')\n",
    "# df_combine = pd.read_csv('all_enzymes_feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = all_enzymes_wildtype_feature.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutant = df_combine.iloc[:,-1280:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1270</th>\n",
       "      <th>1271</th>\n",
       "      <th>1272</th>\n",
       "      <th>1273</th>\n",
       "      <th>1274</th>\n",
       "      <th>1275</th>\n",
       "      <th>1276</th>\n",
       "      <th>1277</th>\n",
       "      <th>1278</th>\n",
       "      <th>1279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015805</td>\n",
       "      <td>-0.033919</td>\n",
       "      <td>0.005356</td>\n",
       "      <td>-0.001142</td>\n",
       "      <td>-0.037829</td>\n",
       "      <td>-0.062076</td>\n",
       "      <td>0.034698</td>\n",
       "      <td>0.074689</td>\n",
       "      <td>0.025458</td>\n",
       "      <td>0.099601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031189</td>\n",
       "      <td>-0.033546</td>\n",
       "      <td>-0.103467</td>\n",
       "      <td>0.056230</td>\n",
       "      <td>-0.052916</td>\n",
       "      <td>-0.003619</td>\n",
       "      <td>-0.020674</td>\n",
       "      <td>-0.058185</td>\n",
       "      <td>0.027794</td>\n",
       "      <td>0.081028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015805</td>\n",
       "      <td>-0.033919</td>\n",
       "      <td>0.005356</td>\n",
       "      <td>-0.001142</td>\n",
       "      <td>-0.037829</td>\n",
       "      <td>-0.062076</td>\n",
       "      <td>0.034698</td>\n",
       "      <td>0.074689</td>\n",
       "      <td>0.025458</td>\n",
       "      <td>0.099601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031189</td>\n",
       "      <td>-0.033546</td>\n",
       "      <td>-0.103467</td>\n",
       "      <td>0.056230</td>\n",
       "      <td>-0.052916</td>\n",
       "      <td>-0.003619</td>\n",
       "      <td>-0.020674</td>\n",
       "      <td>-0.058185</td>\n",
       "      <td>0.027794</td>\n",
       "      <td>0.081028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015805</td>\n",
       "      <td>-0.033919</td>\n",
       "      <td>0.005356</td>\n",
       "      <td>-0.001142</td>\n",
       "      <td>-0.037829</td>\n",
       "      <td>-0.062076</td>\n",
       "      <td>0.034698</td>\n",
       "      <td>0.074689</td>\n",
       "      <td>0.025458</td>\n",
       "      <td>0.099601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031189</td>\n",
       "      <td>-0.033546</td>\n",
       "      <td>-0.103467</td>\n",
       "      <td>0.056230</td>\n",
       "      <td>-0.052916</td>\n",
       "      <td>-0.003619</td>\n",
       "      <td>-0.020674</td>\n",
       "      <td>-0.058185</td>\n",
       "      <td>0.027794</td>\n",
       "      <td>0.081028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015805</td>\n",
       "      <td>-0.033919</td>\n",
       "      <td>0.005356</td>\n",
       "      <td>-0.001142</td>\n",
       "      <td>-0.037829</td>\n",
       "      <td>-0.062076</td>\n",
       "      <td>0.034698</td>\n",
       "      <td>0.074689</td>\n",
       "      <td>0.025458</td>\n",
       "      <td>0.099601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031189</td>\n",
       "      <td>-0.033546</td>\n",
       "      <td>-0.103467</td>\n",
       "      <td>0.056230</td>\n",
       "      <td>-0.052916</td>\n",
       "      <td>-0.003619</td>\n",
       "      <td>-0.020674</td>\n",
       "      <td>-0.058185</td>\n",
       "      <td>0.027794</td>\n",
       "      <td>0.081028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.015805</td>\n",
       "      <td>-0.033919</td>\n",
       "      <td>0.005356</td>\n",
       "      <td>-0.001142</td>\n",
       "      <td>-0.037829</td>\n",
       "      <td>-0.062076</td>\n",
       "      <td>0.034698</td>\n",
       "      <td>0.074689</td>\n",
       "      <td>0.025458</td>\n",
       "      <td>0.099601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031189</td>\n",
       "      <td>-0.033546</td>\n",
       "      <td>-0.103467</td>\n",
       "      <td>0.056230</td>\n",
       "      <td>-0.052916</td>\n",
       "      <td>-0.003619</td>\n",
       "      <td>-0.020674</td>\n",
       "      <td>-0.058185</td>\n",
       "      <td>0.027794</td>\n",
       "      <td>0.081028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6586</th>\n",
       "      <td>0.056222</td>\n",
       "      <td>-0.019059</td>\n",
       "      <td>0.034438</td>\n",
       "      <td>0.042787</td>\n",
       "      <td>-0.081775</td>\n",
       "      <td>0.047643</td>\n",
       "      <td>0.119286</td>\n",
       "      <td>-0.011242</td>\n",
       "      <td>-0.062220</td>\n",
       "      <td>-0.031445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063324</td>\n",
       "      <td>-0.103465</td>\n",
       "      <td>-0.039717</td>\n",
       "      <td>-0.029019</td>\n",
       "      <td>0.053409</td>\n",
       "      <td>-0.129892</td>\n",
       "      <td>0.118203</td>\n",
       "      <td>-0.196604</td>\n",
       "      <td>0.070822</td>\n",
       "      <td>0.114469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6587</th>\n",
       "      <td>0.056222</td>\n",
       "      <td>-0.019059</td>\n",
       "      <td>0.034438</td>\n",
       "      <td>0.042787</td>\n",
       "      <td>-0.081775</td>\n",
       "      <td>0.047643</td>\n",
       "      <td>0.119286</td>\n",
       "      <td>-0.011242</td>\n",
       "      <td>-0.062220</td>\n",
       "      <td>-0.031445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063324</td>\n",
       "      <td>-0.103465</td>\n",
       "      <td>-0.039717</td>\n",
       "      <td>-0.029019</td>\n",
       "      <td>0.053409</td>\n",
       "      <td>-0.129892</td>\n",
       "      <td>0.118203</td>\n",
       "      <td>-0.196604</td>\n",
       "      <td>0.070822</td>\n",
       "      <td>0.114469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6588</th>\n",
       "      <td>0.056222</td>\n",
       "      <td>-0.019059</td>\n",
       "      <td>0.034438</td>\n",
       "      <td>0.042787</td>\n",
       "      <td>-0.081775</td>\n",
       "      <td>0.047643</td>\n",
       "      <td>0.119286</td>\n",
       "      <td>-0.011242</td>\n",
       "      <td>-0.062220</td>\n",
       "      <td>-0.031445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063324</td>\n",
       "      <td>-0.103465</td>\n",
       "      <td>-0.039717</td>\n",
       "      <td>-0.029019</td>\n",
       "      <td>0.053409</td>\n",
       "      <td>-0.129892</td>\n",
       "      <td>0.118203</td>\n",
       "      <td>-0.196604</td>\n",
       "      <td>0.070822</td>\n",
       "      <td>0.114469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6589</th>\n",
       "      <td>0.056222</td>\n",
       "      <td>-0.019059</td>\n",
       "      <td>0.034438</td>\n",
       "      <td>0.042787</td>\n",
       "      <td>-0.081775</td>\n",
       "      <td>0.047643</td>\n",
       "      <td>0.119286</td>\n",
       "      <td>-0.011242</td>\n",
       "      <td>-0.062220</td>\n",
       "      <td>-0.031445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063324</td>\n",
       "      <td>-0.103465</td>\n",
       "      <td>-0.039717</td>\n",
       "      <td>-0.029019</td>\n",
       "      <td>0.053409</td>\n",
       "      <td>-0.129892</td>\n",
       "      <td>0.118203</td>\n",
       "      <td>-0.196604</td>\n",
       "      <td>0.070822</td>\n",
       "      <td>0.114469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6590</th>\n",
       "      <td>0.056222</td>\n",
       "      <td>-0.019059</td>\n",
       "      <td>0.034438</td>\n",
       "      <td>0.042787</td>\n",
       "      <td>-0.081775</td>\n",
       "      <td>0.047643</td>\n",
       "      <td>0.119286</td>\n",
       "      <td>-0.011242</td>\n",
       "      <td>-0.062220</td>\n",
       "      <td>-0.031445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063324</td>\n",
       "      <td>-0.103465</td>\n",
       "      <td>-0.039717</td>\n",
       "      <td>-0.029019</td>\n",
       "      <td>0.053409</td>\n",
       "      <td>-0.129892</td>\n",
       "      <td>0.118203</td>\n",
       "      <td>-0.196604</td>\n",
       "      <td>0.070822</td>\n",
       "      <td>0.114469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6591 rows × 1280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6     \\\n",
       "0     0.015805 -0.033919  0.005356 -0.001142 -0.037829 -0.062076  0.034698   \n",
       "1     0.015805 -0.033919  0.005356 -0.001142 -0.037829 -0.062076  0.034698   \n",
       "2     0.015805 -0.033919  0.005356 -0.001142 -0.037829 -0.062076  0.034698   \n",
       "3     0.015805 -0.033919  0.005356 -0.001142 -0.037829 -0.062076  0.034698   \n",
       "4     0.015805 -0.033919  0.005356 -0.001142 -0.037829 -0.062076  0.034698   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6586  0.056222 -0.019059  0.034438  0.042787 -0.081775  0.047643  0.119286   \n",
       "6587  0.056222 -0.019059  0.034438  0.042787 -0.081775  0.047643  0.119286   \n",
       "6588  0.056222 -0.019059  0.034438  0.042787 -0.081775  0.047643  0.119286   \n",
       "6589  0.056222 -0.019059  0.034438  0.042787 -0.081775  0.047643  0.119286   \n",
       "6590  0.056222 -0.019059  0.034438  0.042787 -0.081775  0.047643  0.119286   \n",
       "\n",
       "          7         8         9     ...      1270      1271      1272  \\\n",
       "0     0.074689  0.025458  0.099601  ...  0.031189 -0.033546 -0.103467   \n",
       "1     0.074689  0.025458  0.099601  ...  0.031189 -0.033546 -0.103467   \n",
       "2     0.074689  0.025458  0.099601  ...  0.031189 -0.033546 -0.103467   \n",
       "3     0.074689  0.025458  0.099601  ...  0.031189 -0.033546 -0.103467   \n",
       "4     0.074689  0.025458  0.099601  ...  0.031189 -0.033546 -0.103467   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "6586 -0.011242 -0.062220 -0.031445  ...  0.063324 -0.103465 -0.039717   \n",
       "6587 -0.011242 -0.062220 -0.031445  ...  0.063324 -0.103465 -0.039717   \n",
       "6588 -0.011242 -0.062220 -0.031445  ...  0.063324 -0.103465 -0.039717   \n",
       "6589 -0.011242 -0.062220 -0.031445  ...  0.063324 -0.103465 -0.039717   \n",
       "6590 -0.011242 -0.062220 -0.031445  ...  0.063324 -0.103465 -0.039717   \n",
       "\n",
       "          1273      1274      1275      1276      1277      1278      1279  \n",
       "0     0.056230 -0.052916 -0.003619 -0.020674 -0.058185  0.027794  0.081028  \n",
       "1     0.056230 -0.052916 -0.003619 -0.020674 -0.058185  0.027794  0.081028  \n",
       "2     0.056230 -0.052916 -0.003619 -0.020674 -0.058185  0.027794  0.081028  \n",
       "3     0.056230 -0.052916 -0.003619 -0.020674 -0.058185  0.027794  0.081028  \n",
       "4     0.056230 -0.052916 -0.003619 -0.020674 -0.058185  0.027794  0.081028  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "6586 -0.029019  0.053409 -0.129892  0.118203 -0.196604  0.070822  0.114469  \n",
       "6587 -0.029019  0.053409 -0.129892  0.118203 -0.196604  0.070822  0.114469  \n",
       "6588 -0.029019  0.053409 -0.129892  0.118203 -0.196604  0.070822  0.114469  \n",
       "6589 -0.029019  0.053409 -0.129892  0.118203 -0.196604  0.070822  0.114469  \n",
       "6590 -0.029019  0.053409 -0.129892  0.118203 -0.196604  0.070822  0.114469  \n",
       "\n",
       "[6591 rows x 1280 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wt.iloc[1,:].sort_values().reset_index(drop=True).plot.line();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wt.iloc[1,:].sort_values().plot.line();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mutant.iloc[1,:].plot.line();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = (wt-mutant)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.320376\n",
       "1       0.481710\n",
       "2       0.312745\n",
       "3      -0.172836\n",
       "4       0.414252\n",
       "          ...   \n",
       "6586    0.675470\n",
       "6587    1.490860\n",
       "6588   -4.357233\n",
       "6589   -2.425898\n",
       "6590   -2.844078\n",
       "Length: 6591, dtype: float32"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combine['difference'] = difference.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = df_combine.query('split == \"test\"')[['seq_id','difference']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.rename(columns ={'difference':'tm'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2413"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
